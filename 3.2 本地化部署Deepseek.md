
探索常用社区资源如Github/Huggingface/Modelscope，如何进行模型下载，并通过VLLM/Ollama/SGLang/Transformer启动模型，进行模型试用。


# 大模型部署实践教程

## 一、GitHub资源使用
### 1.1 查找Llama-Factory项目
1. 访问GitHub官网：[https://github.com](https://github.com)
2. 在搜索栏输入 `Llama-Factory` 
3. 选择星标数高的官方仓库：[hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)


### 1.2 克隆仓库

在我们的AutoDL实例中, 打开JupyterLab
在项目文件夹目录下, 打开**控制台**

```bash
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash && sudo apt-get install git-lfs && git lfs install


克隆github仓库的指令
1. git clone

安装需求库
pip install -r requirements.txt

网络监控：
1. 安装iftop
sudo apt-get install iftop

2. 运行 iftop
sudo iftop

安装jdk
1. 更新apt库
sudo apt update

2. 安装jdk
apt install openjdk-21-jdk

克隆Qwen1.5-0.5B仓库
git clone https://www.modelscope.cn/qwen/Qwen1.5-0.5B.git
```

## 二、Hugging Face模型操作

### 2.1 搜索下载Qwen2.5模型

1. 访问官网：[https://huggingface.co](https://huggingface.co/)
    
2. 搜索栏输入 `Qwen2.5-1.5B-Chat`
    
3. 进入模型页：[Qwen/Qwen2-1.5B-Chat](https://huggingface.co/Qwen/Qwen2-1.5B-Chat)
    

#### 下载方式

```bash
# 使用CLI下载
pip install huggingface_hub
huggingface-cli download Qwen/Qwen2-1.5B-Chat --local-dir ./qwen1.5b

# 或Python代码下载
from huggingface_hub import snapshot_download
snapshot_download(repo_id="Qwen/Qwen2-1.5B-Chat", local_dir="./qwen1.5b")
```