
探索常用社区资源如Github/Huggingface/Modelscope，如何进行模型下载，并通过VLLM/Ollama/SGLang/Transformer启动模型，进行模型试用。


# 大模型部署实践教程

## 一、GitHub资源使用
### 1.1 查找Llama-Factory项目
1. 访问GitHub官网：[https://github.com](https://github.com)
2. 在搜索栏输入 `Llama-Factory` 
3. 选择星标数高的官方仓库：[hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)


### 1.2 克隆仓库

在我们的AutoDL实例中, 打开JupyterLab
在项目文件夹目录下, 打开bash

在curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudg bash && suda apt-get install git-lfs && git lfs install

```bash
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -r requirements.txt
```

## 二、Hugging Face模型操作

### 2.1 搜索下载Qwen2.5模型

1. 访问官网：[https://huggingface.co](https://huggingface.co/)
    
2. 搜索栏输入 `Qwen2.5-1.5B-Chat`
    
3. 进入模型页：[Qwen/Qwen2-1.5B-Chat](https://huggingface.co/Qwen/Qwen2-1.5B-Chat)
    

#### 下载方式

```bash
# 使用CLI下载
pip install huggingface_hub
huggingface-cli download Qwen/Qwen2-1.5B-Chat --local-dir ./qwen1.5b

# 或Python代码下载
from huggingface_hub import snapshot_download
snapshot_download(repo_id="Qwen/Qwen2-1.5B-Chat", local_dir="./qwen1.5b")
```